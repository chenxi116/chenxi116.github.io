---
layout: page
permalink: /
---

<!-- ## About Me -->

<img style="float: left; width: 150px; margin:0 50px 20px 0" src="assets/round.png">

I am a research scientist at Google DeepMind.

I work on Gemini post-training. 

Here is my [CV][cv] and [Google Scholar][scholar].

<br><br>

## Publications

- **Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context**  
Google Gemini Team; Core Contributor  
Technical Report  
[\[arXiv\]][gemini15-arxiv]

- **Gemini: a family of highly capable multimodal models**  
Google Gemini Team; Core Contributor  
Technical Report  
[\[arXiv\]][gemini-arxiv]

- **De-Diffusion Makes Text a Strong Cross-Modal Interface**  
Chen Wei, **Chenxi Liu**, Siyuan Qiao, Zhishuai Zhang, Alan Yuille, Jiahui Yu  
In *Conference on Computer Vision and Pattern Recognition* (**CVPR**), 2024   
[\[arXiv\]][dediffusion-arxiv]

- **LEF: Late-to-Early Temporal Fusion for LiDAR 3D Object Detection**  
Tong He, Pei Sun, Zhaoqi Leng, **Chenxi Liu**, Dragomir Anguelov, Mingxing Tan  
In *International Conference on Intelligent Robots and Systems* (**IROS**), 2023  
[\[arXiv\]][lef-arxiv]

- **MoDAR: Using Motion Forecasting for 3D Object Detection in Point Cloud Sequences**  
Yingwei Li, Charles R. Qi, Yin Zhou, **Chenxi Liu**, Dragomir Anguelov  
In *Conference on Computer Vision and Pattern Recognition* (**CVPR**), 2023  
[\[arXiv\]][modar-arxiv]

- **LidarAugment: Searching for Scalable 3D LiDAR Data Augmentations**  
Zhaoqi Leng, Guowang Li, **Chenxi Liu**, Ekin Dogus Cubuk, Pei Sun, Tong He, Dragomir Anguelov, Mingxing Tan  
In *International Conference on Robotics and Automation* (**ICRA**), 2023  
[\[arXiv\]][lidaraugment-arxiv]

- **SWFormer: Sparse Window Transformer for 3D Object Detection in Point Clouds**   
Pei Sun, Mingxing Tan, Weiyue Wang, **Chenxi Liu**, Fei Xia, Zhaoqi Leng, Dragomir Anguelov  
In *European Conference on Computer Vision* (**ECCV**), 2022  
[\[arXiv\]][swformer-arxiv]

- **LidarNAS: Unifying and Searching Neural Architectures for 3D Point Clouds**  
**Chenxi Liu**, Zhaoqi Leng, Pei Sun, Shuyang Cheng, Charles R. Qi, Yin Zhou, Mingxing Tan, Dragomir Anguelov  
In *European Conference on Computer Vision* (**ECCV**), 2022  
[\[arXiv\]][lidarnas-arxiv] [\[Poster\]][lidarnas-poster] [\[Video\]][lidarnas-video]

- **Multi-Class 3D Object Detection with Single-Class Supervision**  
Mao Ye, **Chenxi Liu**, Maoqing Yao, Weiyue Wang, Zhaoqi Leng, Charles R. Qi, Dragomir Anguelov  
In *International Conference on Robotics and Automation* (**ICRA**), 2022  
[\[arXiv\]][scs-arxiv]

- **PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions**  
Zhaoqi Leng, Mingxing Tan, **Chenxi Liu**, Ekin Dogus Cubuk, Xiaojie Shi, Shuyang Cheng, Dragomir Anguelov  
In *International Conference on Learning Representations* (**ICLR**), 2022  
[\[arXiv\]][polyloss-arxiv]

- **Scene Transformer: A unified architecture for predicting multiple agent trajectories**  
Jiquan Ngiam, Benjamin Caine, Vijay Vasudevan, Zhengdong Zhang, Hao-Tien Lewis Chiang, Jeffrey Ling, Rebecca Roelofs, Alex Bewley, **Chenxi Liu**, Ashish Venugopal, David Weiss, Ben Sapp, Zhifeng Chen, Jonathon Shlens  
In *International Conference on Learning Representations* (**ICLR**), 2022  
[\[arXiv\]][st-arxiv]

- **Large Scale Interactive Motion Forecasting for Autonomous Driving : The Waymo Open Motion Dataset**  
Scott Ettinger, Shuyang Cheng, Benjamin Caine, **Chenxi Liu**, Hang Zhao, Sabeek Pradhan, Yuning Chai, Ben Sapp, Charles Qi, Yin Zhou, Zoey Yang, Aurelien Chouard, Pei Sun, Jiquan Ngiam, Vijay Vasudevan, Alexander McCauley, Jonathon Shlens, Dragomir Anguelov  
In *International Conference on Computer Vision* (**ICCV**), 2021 **Oral**    
[\[arXiv\]][womd-arxiv]

- **Progressive Stage-wise Learning for Unsupervised Feature Representation Enhancement**   
Zefan Li, **Chenxi Liu**, Alan Yuille, Bingbing Ni, Wenjun Zhang, Wen Gao  
In *Conference on Computer Vision and Pattern Recognition* (**CVPR**), 2021  
[\[arXiv\]][psl-arxiv]

- **Deep Nets: What have they ever done for Vision?**  
Alan Yuille, **Chenxi Liu**  
*International Journal of Computer Vision* (**IJCV**), 2021  
[\[arXiv\]][deepnets-arxiv] [\[CBMM\]][deepnets-cbmm] [\[Blog\]][deepnets-blog]

- **Are Labels Necessary for Neural Architecture Search?**  
**Chenxi Liu**, Piotr Dollar, Kaiming He, Ross Girshick, Alan Yuille, Saining Xie  
In *European Conference on Computer Vision* (**ECCV**), 2020 **Spotlight**    
[\[arXiv\]][unnas-arxiv] [\[Paper\]][unnas-paper] [\[Suppl\]][unnas-suppl] [\[Slides (Short)\]][unnas-slides-short] [\[Slides (Long)\]][unnas-slides-long] [\[Video (Short)\]][unnas-video-short] [\[Video (Long)\]][unnas-video-long] [\[Code\]][unnas-code]

- **Identifying Model Weakness with Adversarial Examiner**  
Michelle Shu, **Chenxi Liu**, Weichao Qiu, Alan Yuille  
In *AAAI Conference on Artificial Intelligence* (**AAAI**), 2020  
[\[arXiv\]][advexaminer-arxiv] [\[Paper\]][advexaminer-paper] [\[Slides\]][advexaminer-slides] [\[Poster\]][advexaminer-poster]

- **Rethinking Normalization and Elimination Singularity in Neural Networks**  
Siyuan Qiao, Huiyu Wang, **Chenxi Liu**, Wei Shen, Alan Yuille  
arXiv preprint, 2019  
[\[arXiv\]][bcn-arxiv] [\[Code\]][bcn-code]

- **V-NAS: Neural Architecture Search for Volumetric Medical Image Segmentation**  
Zhuotun Zhu, **Chenxi Liu**, Dong Yang, Alan Yuille, Daguang Xu  
In *International Conference on 3D Vision* (**3DV**), 2019  
[\[arXiv\]][vnas-arxiv]

- **Weight Standardization**  
Siyuan Qiao, Huiyu Wang, **Chenxi Liu**, Wei Shen, Alan Yuille  
arXiv preprint, 2019  
[\[arXiv\]][ws-arxiv] [\[Code\]][ws-code]

- **Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation**  
**Chenxi Liu**, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan Yuille, Li Fei-Fei  
In *Conference on Computer Vision and Pattern Recognition* (**CVPR**), 2019 **Oral**  
[\[arXiv\]][auto-deeplab-arxiv] [\[Paper\]][auto-deeplab-paper] [\[Slides\]][auto-deeplab-slides] [\[Poster\]][auto-deeplab-poster] [\[Code\]][auto-deeplab-code]

- **Adversarial Attacks Beyond the Image Space**  
Xiaohui Zeng, **Chenxi Liu**, Yu-Siang Wang, Weichao Qiu, Lingxi Xie, Yu-Wing Tai, Chi Keung Tang, Alan Yuille  
In *Conference on Computer Vision and Pattern Recognition* (**CVPR**), 2019 **Oral**  
[\[arXiv\]][advphy-arxiv] [\[Paper\]][advphy-paper] [\[Suppl\]][advphy-suppl] [\[Slides\]][advphy-slides] [\[Poster\]][advphy-poster]

- **CLEVR-Ref+: Diagnosing Visual Reasoning with Referring Expressions**  
Runtao Liu, **Chenxi Liu**, Yutong Bai, Alan Yuille  
In *Conference on Computer Vision and Pattern Recognition* (**CVPR**), 2019  
[\[Project\]][clevr-ref+-page] [\[arXiv\]][clevr-ref+-arxiv] [\[Paper\]][clevr-ref+-paper] [\[Suppl\]][clevr-ref+-suppl] [\[Poster\]][clevr-ref+-poster]

- **Progressive Neural Architecture Search**  
**Chenxi Liu**, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, Kevin Murphy  
In *European Conference on Computer Vision* (**ECCV**), 2018 **Oral**    
[\[arXiv\]][pnas-arxiv] [\[Paper\]][pnas-paper] [\[Suppl\]][pnas-suppl] [\[Slides\]][pnas-slides] [\[Poster\]][pnas-poster] [\[Blog\]][automl-blog] [\[Code (TF official)\]][pnas-tf-official] [\[Code (TF simplified)\]][pnas-tf-simplified] [\[Code (PyTorch)\]][pnas-pytorch]

- **Few-Shot Image Recognition by Predicting Parameters from Activations**  
Siyuan Qiao, **Chenxi Liu**, Wei Shen, Alan Yuille  
In *Conference on Computer Vision and Pattern Recognition* (**CVPR**), 2018 **Spotlight**  
[\[arXiv\]][fewshot-arxiv] [\[Code\]][fewshot-code]

- **Scene Graph Parsing as Dependency Parsing**  
Yu-Siang Wang, **Chenxi Liu**, Xiaohui Zeng, Alan Yuille  
In *North American Chapter of the Association for Computational Linguistics* (**NAACL**), 2018 **Oral**  
[\[arXiv\]][sgparser-arxiv] [\[Paper\]][sgparser-paper] [\[Slides\]][sgparser-slides] [\[Video\]][sgparser-video] [\[Code\]][sgparser-code]

- **Recurrent Multimodal Interaction for Referring Image Segmentation**  
**Chenxi Liu**, Zhe Lin, Xiaohui Shen, Jimei Yang, Xin Lu, Alan Yuille  
In *International Conference on Computer Vision* (**ICCV**), 2017  
[\[arXiv\]][phrasecut-arxiv] [\[Paper\]][phrasecut-paper] [\[Suppl\]][phrasecut-suppl] [\[Poster\]][phrasecut-poster] [\[Code\]][phrasecut-code]

- **SORT: Second-Order Response Transform for Visual Recognition**  
Yan Wang, Lingxi Xie, **Chenxi Liu**, Siyuan Qiao, Ya Zhang, Wenjun Zhang, Qi Tian, Alan Yuille  
In *International Conference on Computer Vision* (**ICCV**), 2017  
[\[arXiv\]][sort-arxiv]

- **ScaleNet: Guiding Object Proposal Generation in Supermarkets and Beyond**  
Siyuan Qiao, Wei Shen, Weichao Qiu, **Chenxi Liu**, Alan Yuille  
In *International Conference on Computer Vision* (**ICCV**), 2017  
[\[arXiv\]][scalenet-arxiv] [\[Code\]][scalenet-code]

- **Attention Correctness in Neural Image Captioning**  
**Chenxi Liu**, Junhua Mao, Fei Sha, Alan Yuille  
In *AAAI Conference on Artificial Intelligence* (**AAAI**), 2017  
[\[arXiv\]][attn-corr-arxiv] [\[Paper\]][attn-corr-paper] [\[Suppl\]][attn-corr-suppl] [\[Poster\]][attn-corr-poster] [\[Code\]][attn-corr-code]

- **Rent3D: Floor-Plan Priors for Monocular Layout Estimation**  
**Chenxi Liu**\*, Alexander Schwing\*, Kaustav Kundu, Raquel Urtasun, Sanja Fidler  
In *Conference on Computer Vision and Pattern Recognition* (**CVPR**), 2015 **Oral**  
[\[Project\]][rent3d-page] [\[Paper\]][rent3d-paper] [\[Suppl\]][rent3d-suppl] [\[Slides\]][rent3d-slides] [\[Poster\]][rent3d-poster] [\[Video\]][rent3d-video] [\[Two Minute Papers\]][rent3d-2min]


## Miscellaneous

Me playing:

- [Bach: Goldberg Variations][goldberg] (2020)

- [Chopin: Ballade No.1][ballade1] (2021)

- [Beethoven: Piano Sonata No.1][sonata1] (2021)

- [Beethoven: Piano Sonata No.2][sonata2] (2022)

- [Beethoven: Piano Sonata No.3][sonata3] (2023)

- [A voice and piano recital][recital] (2023)

- [Beethoven: Piano Sonata No.4][sonata4] (2024)


[bdp]: https://en.wikipedia.org/wiki/Bloomberg_Distinguished_Professorships
[alan]: https://cs.jhu.edu/~ayuille/
[jason]: https://cs.jhu.edu/~jason/
[cv]: https://chenxi116.github.io/cv/CV_Chenxi_Liu.pdf
[scholar]: https://scholar.google.com/citations?user=qvRsU00AAAAJ&hl=en
[waymo-intern]: https://waymo.com/joinus/2435634/
[minds]: https://www.minds.jhu.edu/awards/minds-doctoral-dissertation-award/
[goldberg]: https://youtu.be/ywWSC1sNEd4
[ballade1]: https://youtu.be/EsCYUzZvySo
[sonata1]: https://youtu.be/pSdCUDk5Pww
[sonata2]: https://youtu.be/MeFw4eIgwjM
[sonata3]: https://youtu.be/LUS5_Wniu5E
[sonata4]: https://youtu.be/NMQmlgETaqs
[recital]: https://www.youtube.com/playlist?list=PLWkXI1ejmNYQ-PJpWx2Mqwp4sAyVwTOR_
[snap-fellowship]: https://snapresearchfellowship.splashthat.com
[nvidia-fellowship]: https://blogs.nvidia.com/blog/2018/04/04/nvidia-graduate-fellowship-program/
[google-fellowship]: https://ai.googleblog.com/2019/09/announcement-of-2019-fellowship.html
[gemini15-arxiv]: https://arxiv.org/abs/2403.05530
[gemini-arxiv]: https://arxiv.org/abs/2312.11805
[dediffusion-arxiv]: https://arxiv.org/abs/2311.00618
[lef-arxiv]: https://arxiv.org/abs/2309.16870
[modar-arxiv]: https://arxiv.org/abs/2306.03206
[lidaraugment-arxiv]: https://arxiv.org/abs/2210.13488
[swformer-arxiv]: https://arxiv.org/abs/2210.07372
[lidarnas-arxiv]: https://arxiv.org/abs/2210.05018
[lidarnas-poster]: https://chenxi116.github.io/posters/5318.pdf
[lidarnas-video]: https://chenxi116.github.io/videos/5318.mp4
[scs-arxiv]: https://arxiv.org/abs/2205.05703
[polyloss-arxiv]: https://arxiv.org/abs/2204.12511
[st-arxiv]: https://arxiv.org/abs/2106.08417
[womd-arxiv]: https://arxiv.org/abs/2104.10133
[psl-arxiv]: https://arxiv.org/abs/2106.05554
[unnas-arxiv]: https://arxiv.org/abs/2003.12056
[unnas-paper]: https://chenxi116.github.io/papers/unnas_eccv20.pdf
[unnas-suppl]: https://chenxi116.github.io/papers/unnas_suppl.pdf
[unnas-slides-short]: https://chenxi116.github.io/slides/unnas-talk-eccv-short.pdf
[unnas-slides-long]: https://chenxi116.github.io/slides/unnas-talk-eccv-long.pdf
[unnas-video-short]: https://www.youtube.com/watch?v=j9zgskDGbMg
[unnas-video-long]: https://www.youtube.com/watch?v=pz-uELduTLI
[unnas-code]: https://github.com/facebookresearch/unnas
[advexaminer-arxiv]: https://arxiv.org/abs/1911.11230
[advexaminer-paper]: https://chenxi116.github.io/papers/advexaminer_aaai20.pdf
[advexaminer-slides]: https://chenxi116.github.io/slides/advexaminer-talk-aaai.pdf
[advexaminer-poster]: https://chenxi116.github.io/posters/advexaminer_poster.pdf
[bcn-arxiv]: https://arxiv.org/abs/1911.09738
[bcn-code]: https://github.com/joe-siyuan-qiao/Batch-Channel-Normalization
[vnas-arxiv]: https://arxiv.org/abs/1906.02817
[ws-arxiv]: https://arxiv.org/abs/1903.10520
[ws-code]: https://github.com/joe-siyuan-qiao/WeightStandardization
[auto-deeplab-arxiv]: https://arxiv.org/abs/1901.02985
[auto-deeplab-paper]: https://chenxi116.github.io/papers/auto_deeplab_cvpr19.pdf
[auto-deeplab-slides]: https://chenxi116.github.io/slides/auto-deeplab-talk-cvpr.pdf
[auto-deeplab-poster]: https://chenxi116.github.io/posters/auto_deeplab_poster.pdf
[auto-deeplab-code]: https://github.com/tensorflow/models/tree/master/research/deeplab/
[clevr-ref+-page]: https://chenxi116.github.io/2019/clevr-ref+.html
[clevr-ref+-arxiv]: https://arxiv.org/abs/1901.00850
[clevr-ref+-paper]: https://chenxi116.github.io/papers/clevr_ref+_cvpr19.pdf
[clevr-ref+-suppl]: https://chenxi116.github.io/papers/clevr_ref+_suppl.pdf
[clevr-ref+-poster]: https://chenxi116.github.io/posters/clevr_ref+_poster.pdf
[deepnets-arxiv]: https://arxiv.org/abs/1805.04025
[deepnets-cbmm]: https://cbmm.mit.edu/sites/default/files/publications/CBMM-Memo-088.pdf
[deepnets-blog]: https://thegradient.pub/the-limitations-of-visual-deep-learning-and-how-we-might-fix-them/
[sgparser-arxiv]: https://arxiv.org/abs/1803.09189
[sgparser-paper]: https://chenxi116.github.io/papers/sgparser_naacl18.pdf
[sgparser-slides]: https://chenxi116.github.io/slides/sgparser-talk-naacl.pdf
[sgparser-video]: https://vimeo.com/276453229
[sgparser-code]: https://github.com/Yusics/bist-parser/tree/sgparser
[pnas-arxiv]: https://arxiv.org/abs/1712.00559
[pnas-paper]: https://chenxi116.github.io/papers/pnas_eccv18.pdf
[pnas-suppl]: https://chenxi116.github.io/papers/pnas_suppl.pdf
[pnas-slides]: https://chenxi116.github.io/slides/pnas-talk-eccv.pdf
[pnas-poster]: https://chenxi116.github.io/posters/pnas_poster.pdf
[pnas-tf-official]: https://github.com/tensorflow/models/tree/master/research/slim#Pretrained
[pnas-tf-simplified]: https://github.com/chenxi116/PNASNet.TF
[pnas-pytorch]: https://github.com/chenxi116/PNASNet.pytorch
[automl-blog]: https://www.blog.google/topics/google-cloud/cloud-automl-making-ai-accessible-every-business/
[advphy-arxiv]: https://arxiv.org/abs/1711.07183
[advphy-paper]: https://chenxi116.github.io/papers/advphy_cvpr19.pdf
[advphy-suppl]: https://chenxi116.github.io/papers/advphy_suppl.pdf
[advphy-slides]: https://chenxi116.github.io/slides/advphy-talk-cvpr.pdf
[advphy-poster]: https://chenxi116.github.io/posters/advphy_poster.pdf
[fewshot-arxiv]: https://arxiv.org/abs/1706.03466
[fewshot-code]: https://github.com/joe-siyuan-qiao/FewShot-CVPR
[scalenet-arxiv]: https://arxiv.org/abs/1704.06752
[scalenet-code]: https://github.com/joe-siyuan-qiao/ScaleNet
[phrasecut-arxiv]: https://arxiv.org/abs/1703.07939
[phrasecut-paper]: https://chenxi116.github.io/papers/phrasecut_iccv17.pdf
[phrasecut-suppl]: https://chenxi116.github.io/papers/phrasecut_suppl.pdf
[phrasecut-poster]: https://chenxi116.github.io/posters/phrasecut_poster.pdf
[phrasecut-code]: https://github.com/chenxi116/TF-phrasecut-public
[sort-arxiv]: https://arxiv.org/abs/1703.06993
[attn-corr-arxiv]: https://arxiv.org/abs/1605.09553
[attn-corr-paper]: https://chenxi116.github.io/papers/attn_corr_aaai17.pdf
[attn-corr-suppl]: https://chenxi116.github.io/papers/attn_corr_suppl.pdf
[attn-corr-poster]: https://chenxi116.github.io/posters/attn_corr_poster.pdf
[attn-corr-code]: https://github.com/chenxi116/arctic-captions/tree/attn-corr
[rent3d-page]: http://www.cs.toronto.edu/~fidler/projects/rent3D.html
[rent3d-paper]: https://chenxi116.github.io/papers/rent3d_cvpr15.pdf
[rent3d-suppl]: https://chenxi116.github.io/papers/rent3d_suppl.pdf
[rent3d-slides]: https://chenxi116.github.io/slides/rent3d-talk-cvpr.pdf
[rent3d-poster]: https://chenxi116.github.io/posters/rent3d_poster.pdf
[rent3d-video]: http://techtalks.tv/talks/rent3d-floor-plan-priors-for-monocular-layout-estimation/61611/
[rent3d-2min]: https://www.youtube.com/watch?v=UBORpapdAfU
